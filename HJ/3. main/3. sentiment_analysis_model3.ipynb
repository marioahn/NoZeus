{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감성분석 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install scikit-learn\n",
    "# ! pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from collections import Counter\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from konlpy.tag import Mecab\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "warnings.filterwarnings(action = 'ignore') # warning 메시지 표시x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 훈련모델Ⅲ - 214,060개 (7:3)\n",
    "- 네이버+쿠팡 리뷰합친 데이터에서,\n",
    "- 7:3비율로 나눠서 훈련 -> 평가 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 리뷰의 개수 : 160545\n",
      "테스트용 리뷰의 개수 : 53515\n"
     ]
    }
   ],
   "source": [
    "model3_naver_coupang = pd.read_excel('(4)all_reviews_214060.xlsx') # 214,060개\n",
    "\n",
    "# 0. 훈련 데이터와 테스트 데이터를 3:1 비율로 분리\n",
    "train_data, test_data = train_test_split(model3_naver_coupang, test_size = 0.25, random_state = 42)\n",
    "\n",
    "print('훈련용 리뷰의 개수 :', len(train_data))\n",
    "print('테스트용 리뷰의 개수 :', len(test_data))\n",
    "# 훈련용 리뷰의 개수 : 160545\n",
    "# 테스트용 리뷰의 개수 : 53515\n",
    "\n",
    "\n",
    "# 1. 라벨 분포 확인\n",
    "train_data['label'].value_counts()\n",
    "# 1    85144\n",
    "# 0    75401\n",
    "\n",
    "test_data['label'].value_counts()\n",
    "# 1    28308\n",
    "# 0    25207\n",
    "\n",
    "# 2. 한글 외의 문자 제거\n",
    "train_data['reviews'] = train_data['reviews'].apply(lambda x : re.sub(r'[^ ㄱ-ㅣ가-힣]+', \" \", x))\n",
    "test_data['reviews'] = test_data['reviews'].apply(lambda x : re.sub(r'[^ ㄱ-ㅣ가-힣]+', \" \", x))\n",
    "\n",
    "# train_data.head()\n",
    "# test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<160545x160305 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4127203 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 분석 모델 구축 전 작업\n",
    "\n",
    "# 1)형태소 분석 - 문장을 토큰화\n",
    "okt = Okt()\n",
    "def okt_tokenizer(text):\n",
    "    tokens = okt.morphs(text)\n",
    "    return tokens\n",
    "\n",
    "# 2)TF-IDF 벡터화에 사용할 tfidf 객체 생성 -> 벡터로 변환(transform)\n",
    "tfidf = TfidfVectorizer(tokenizer=okt_tokenizer, ngram_range=(1,2), min_df=3, max_df=0.9)\n",
    "tfidf.fit(train_data['reviews'])\n",
    "model3_train_tfidf = tfidf.transform(train_data['reviews'])\n",
    "model3_train_tfidf\n",
    "\n",
    "# 18분 14초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "{'C': 3.5} 0.9162\n"
     ]
    }
   ],
   "source": [
    "# 4. 분석 모델 구축\n",
    "\n",
    "SA_lr = LogisticRegression(random_state=0)\n",
    "\n",
    "SA_lr.fit(model3_train_tfidf, train_data['label'])\n",
    "\n",
    "params = {'C': [1,3,3.5,4,4.5,5]}\n",
    "SA_lr_grid_cv = GridSearchCV(SA_lr, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "\n",
    "SA_lr_grid_cv.fit(model3_train_tfidf, train_data['label'])\n",
    "\n",
    "print(SA_lr_grid_cv.best_params_, round(SA_lr_grid_cv.best_score_, 4))\n",
    "\n",
    "SA_lr_best1 = SA_lr_grid_cv.best_estimator_ \n",
    "\n",
    "# {'C': 3.5} 0.9162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감성 분석 정확도 :  0.918\n"
     ]
    }
   ],
   "source": [
    "# 5. 분석 모델 평가 - 모델 정확도 확인\n",
    "\n",
    "model3_test_tfidf = tfidf.transform(test_data['reviews'])\n",
    "\n",
    "test_predict = SA_lr_best1.predict(model3_test_tfidf)\n",
    "\n",
    "print('감성 분석 정확도 : ', round(accuracy_score(test_data['label'], test_predict), 3))\n",
    "# 감성 분류 모델의 정확도가 91.8%!\n",
    "# (3분 14초)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why? \n",
    "- 흠..model1에 비해 정확도가 떨어질 것이라 생각했는데, 오히려 오름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# todo: 정확도 제일 높은걸로 예측모델 만들기 - https://wikidocs.net/94600 여기있는걸로 - \"x퍼확률\"로 긍정,부정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
