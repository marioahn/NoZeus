{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감성분석 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install scikit-learn\n",
    "# ! pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_16644\\1958826253.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from collections import Counter\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from konlpy.tag import Mecab\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "warnings.filterwarnings(action = 'ignore') # warning 메시지 표시x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 훈련모델Ⅳ - 214,060개로 먼저 선훈련\n",
    "- 네이버+쿠팡 리뷰합친 데이터로 먼저 훈련을 진행하고,\n",
    "- 쿠팡데이터로만 재평가 실시\n",
    "- 214,060 : 14,060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 리뷰의 개수 : 214060\n"
     ]
    }
   ],
   "source": [
    "model4_naver_coupang = pd.read_excel('(4)all_reviews_214060.xlsx') # 214,060개\n",
    "test_data = pd.read_excel('(3)coupang_reviews.xlsx') # 14,060개\n",
    "\n",
    "# 0. 훈련 데이터와 테스트 데이터를 3:1 비율로 분리\n",
    "train_data = model4_naver_coupang\n",
    "\n",
    "print('훈련용 리뷰의 개수 :', len(train_data))\n",
    "# 훈련용 리뷰의 개수 : 160545\n",
    "\n",
    "\n",
    "# 2. 한글 외의 문자 제거\n",
    "train_data['reviews'] = train_data['reviews'].apply(lambda x : re.sub(r'[^ ㄱ-ㅣ가-힣]+', \" \", x))\n",
    "test_data['reviews'] = test_data['reviews'].apply(lambda x : re.sub(r'[^ ㄱ-ㅣ가-힣]+', \" \", x))\n",
    "\n",
    "# train_data.head()\n",
    "# test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<214060x205025 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5607484 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 분석 모델 구축 전 작업\n",
    "\n",
    "# 1)형태소 분석 - 문장을 토큰화\n",
    "okt = Okt()\n",
    "def okt_tokenizer(text):\n",
    "    tokens = okt.morphs(text)\n",
    "    return tokens\n",
    "\n",
    "# 2)TF-IDF 벡터화에 사용할 tfidf 객체 생성 -> 벡터로 변환(transform)\n",
    "tfidf = TfidfVectorizer(tokenizer=okt_tokenizer, ngram_range=(1,2), min_df=3, max_df=0.9)\n",
    "tfidf.fit(train_data['reviews'])\n",
    "model4_train_tfidf = tfidf.transform(train_data['reviews'])\n",
    "model4_train_tfidf\n",
    "\n",
    "# 20분 41초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "{'C': 3.5} 0.8977\n"
     ]
    }
   ],
   "source": [
    "# 4. 분석 모델 구축\n",
    "\n",
    "SA_lr = LogisticRegression(random_state=0)\n",
    "\n",
    "SA_lr.fit(model4_train_tfidf, train_data['label'])\n",
    "\n",
    "params = {'C': [1,3,3.5,4,4.5,5]}\n",
    "SA_lr_grid_cv = GridSearchCV(SA_lr, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "\n",
    "SA_lr_grid_cv.fit(model4_train_tfidf, train_data['label'])\n",
    "\n",
    "print(SA_lr_grid_cv.best_params_, round(SA_lr_grid_cv.best_score_, 4))\n",
    "\n",
    "SA_lr_best1 = SA_lr_grid_cv.best_estimator_ \n",
    "\n",
    "# {'C': 3.5} 0.8977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감성 분석 정확도 :  0.98\n"
     ]
    }
   ],
   "source": [
    "# 5. 분석 모델 평가 - 모델 정확도 확인\n",
    "\n",
    "model4_test_tfidf = tfidf.transform(test_data['reviews'])\n",
    "\n",
    "test_predict = SA_lr_best1.predict(model4_test_tfidf)\n",
    "\n",
    "print('감성 분석 정확도 : ', round(accuracy_score(test_data['label'], test_predict), 3))\n",
    "# 감성 분류 모델의 정확도가 98%! -> 이게 바로 오퍼피팅의 끝\n",
    "# (2분 2초)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why? \n",
    "- 흠..model1에 비해 정확도가 떨어질 것이라 생각했는데, 오히려 오름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
